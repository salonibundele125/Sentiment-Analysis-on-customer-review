{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6224b1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import contractions\n",
    "from unidecode import unidecode\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from autocorrect import Speller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17d82f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I grew up (b. 1965) watching and loving the Th...      0\n",
       "1  When I put this movie in my DVD player, and sa...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Train.csv')\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae2280ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     False\n",
       "label    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isin([\"can't\"]).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cff1c65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.replace({\"can't\":\"can not\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ef2a02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I grew up (b. 1965) watching and loving the Thunderbirds. All my mates at school watched. We played \"Thunderbirds\" before school, during lunch and after school. We all wanted to be Virgil or Scott. No one wanted to be Alan. Counting down from 5 became an art form. I took my children to see the movie hoping they would get a glimpse of what I loved as a child. How bitterly disappointing. The only high point was the snappy theme tune. Not that it could compare with the original score of the Thunderbirds. Thankfully early Saturday mornings one television channel still plays reruns of the series Gerry Anderson and his wife created. Jonatha Frakes should hand in his directors chair, his version was completely hopeless. A waste of film. Utter rubbish. A CGI remake may be acceptable but replacing marionettes with Homo sapiens subsp. sapiens was a huge error of judgment.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "287adc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "#1. remove spaces, newlines\n",
    "def remove_spaces(data):\n",
    "    clean_text = data.replace('\\\\n',' ').replace('\\t',' ').replace('//',' ')\n",
    "    return clean_text\n",
    "\n",
    "#2. Contraction mapping\n",
    "def expand_text(data):\n",
    "    expanded_text = contractions.fix(data)\n",
    "    return expanded_text\n",
    "\n",
    "#3. handling accented characters\n",
    "def handling_accented(data):\n",
    "    fixed_text = unidecode(data)\n",
    "    return fixed_text\n",
    "\n",
    "#4. Cleaning\n",
    "stopword_list = stopwords.words('english')\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('not')\n",
    "stopword_list.remove('nor')\n",
    "\n",
    "def clean_data(data):\n",
    "    tokens = word_tokenize(data)\n",
    "    clean_text = [word.lower() for word in tokens if (word not in punctuation) and (word.lower() not in stopword_list) and (len(word)>2) and (word.isalpha())]\n",
    "    return clean_text\n",
    "\n",
    "# 5. Autocorrection\n",
    "def autorrection(data):\n",
    "    spell = Speller(lang='en')\n",
    "    corrected_text = spell(data)\n",
    "    return corrected_text\n",
    "\n",
    "# 6. Lemmatization\n",
    "def lemmatization(data):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    final_data = []\n",
    "    for word in data:\n",
    "        lemmatized_word = lemmatizer.lemmatize(word)\n",
    "        final_data.append(lemmatized_word)\n",
    "    return ' '.join(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa03a246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count vectorizer and TFIDF\n",
    "# string format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a71d7be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data leakage\n",
    "x_train,x_test,y_train,y_test = train_test_split(data.text,data.label,test_size=0.25,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0700485",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text_train = x_train.apply(remove_spaces)\n",
    "clean_text_test = x_test.apply(remove_spaces)\n",
    "\n",
    "clean_text_train = clean_text_train.apply(expand_text)\n",
    "clean_text_test = clean_text_test.apply(expand_text)\n",
    "\n",
    "clean_text_train = clean_text_train.apply(handling_accented)\n",
    "clean_text_test = clean_text_test.apply(handling_accented)\n",
    "\n",
    "clean_text_train = clean_text_train.apply(clean_data)\n",
    "clean_text_test = clean_text_test.apply(clean_data)\n",
    "\n",
    "clean_text_train = clean_text_train.apply(lemmatization)\n",
    "clean_text_test = clean_text_test.apply(lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e01726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for Count Vectorizer and TFIDF\n",
    "max_df >> by default value >> 1.0 >> 100%\n",
    "100 documents >>>> \n",
    "max_df = 0.95 >> 95% \n",
    "100 documents >> 95 => \n",
    "\n",
    "min_df >> by default value >> 1 >> single document\n",
    "min_df >> 15 >> 15 documents\n",
    "15=> \n",
    "\n",
    "max_features >> 1000 \n",
    "\n",
    "stopword = 'english'\n",
    "\n",
    "lower_case = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c105ba53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26898    fifth grade language art teacher read book stu...\n",
       "27635    low budget brit pop melodrama focus girl want ...\n",
       "3036     well watched movie little year ago pulled dust...\n",
       "5604     would almost give however confusing part well ...\n",
       "36111    full length feature film world bridge found fi...\n",
       "                               ...                        \n",
       "6265     movie one worst movie ever seen life waste tim...\n",
       "11284    movie inspiring anyone tough jam whether finan...\n",
       "38158    east side story documentary musical comedy sta...\n",
       "860      one boot one point doctor assistant refers wor...\n",
       "15795    movie horrible lighting terrible camera moveme...\n",
       "Name: text, Length: 30000, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a678957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count vectorizer\n",
    "count = CountVectorizer(max_df=0.95,max_features=1000)\n",
    "count_val_train = count.fit_transform(clean_text_train)\n",
    "count_val_test = count.transform(clean_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06f76e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<30000x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1617735 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_val_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d9c8b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_val_train.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "826c6418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_val_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56b1e327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ability', 'able', 'absolutely', 'accent', 'across', 'act',\n",
       "       'acted', 'acting', 'action', 'actor', 'actress', 'actual',\n",
       "       'actually', 'adaptation', 'add', 'admit', 'adult', 'adventure',\n",
       "       'age', 'ago', 'agree', 'air', 'alien', 'alive', 'almost', 'alone',\n",
       "       'along', 'already', 'also', 'although', 'always', 'amazing',\n",
       "       'america', 'american', 'among', 'amount', 'animal', 'animation',\n",
       "       'annoying', 'another', 'answer', 'anyone', 'anything', 'anyway',\n",
       "       'apart', 'apparently', 'appeal', 'appear', 'appearance', 'appears',\n",
       "       'appreciate', 'army', 'around', 'art', 'aside', 'ask', 'aspect',\n",
       "       'atmosphere', 'attack', 'attempt', 'attention', 'audience',\n",
       "       'average', 'avoid', 'award', 'away', 'awesome', 'awful', 'baby',\n",
       "       'back', 'background', 'bad', 'badly', 'band', 'barely', 'based',\n",
       "       'basic', 'basically', 'battle', 'beautiful', 'beauty', 'became',\n",
       "       'become', 'becomes', 'begin', 'beginning', 'behind', 'belief',\n",
       "       'believable', 'believe', 'best', 'better', 'beyond', 'big',\n",
       "       'biggest', 'bill', 'bit', 'bizarre', 'black', 'blood', 'blue',\n",
       "       'body', 'book', 'bored', 'boring', 'bother', 'box', 'boy', 'brain',\n",
       "       'break', 'brilliant', 'bring', 'brings', 'british', 'brother',\n",
       "       'brought', 'budget', 'bunch', 'business', 'buy', 'call', 'called',\n",
       "       'came', 'camera', 'camp', 'car', 'care', 'career', 'carry',\n",
       "       'cartoon', 'case', 'cast', 'casting', 'cat', 'catch', 'caught',\n",
       "       'century', 'certain', 'certainly', 'chance', 'change', 'changed',\n",
       "       'channel', 'character', 'chase', 'cheap', 'check', 'cheesy',\n",
       "       'child', 'choice', 'christmas', 'cinema', 'cinematography', 'city',\n",
       "       'class', 'classic', 'clear', 'clearly', 'clever', 'cliche',\n",
       "       'close', 'college', 'color', 'come', 'comedy', 'comic', 'coming',\n",
       "       'comment', 'common', 'company', 'compared', 'complete',\n",
       "       'completely', 'computer', 'concept', 'conclusion', 'consider',\n",
       "       'considering', 'control', 'convincing', 'cool', 'cop', 'copy',\n",
       "       'costume', 'could', 'country', 'couple', 'course', 'cover', 'crap',\n",
       "       'crazy', 'create', 'created', 'creature', 'credit', 'creepy',\n",
       "       'crew', 'crime', 'critic', 'cry', 'culture', 'cut', 'cute',\n",
       "       'dance', 'dancing', 'dark', 'date', 'daughter', 'david', 'day',\n",
       "       'dead', 'deal', 'death', 'decent', 'decide', 'decided', 'decides',\n",
       "       'deep', 'definitely', 'depth', 'deserves', 'despite', 'detail',\n",
       "       'development', 'dialog', 'dialogue', 'die', 'died', 'different',\n",
       "       'difficult', 'directed', 'directing', 'direction', 'director',\n",
       "       'disappointed', 'disney', 'doctor', 'documentary', 'dog', 'done',\n",
       "       'door', 'doubt', 'drama', 'dramatic', 'dream', 'drive', 'drug',\n",
       "       'due', 'dull', 'dumb', 'dvd', 'earlier', 'early', 'earth',\n",
       "       'easily', 'easy', 'editing', 'effect', 'effort', 'either',\n",
       "       'element', 'else', 'emotion', 'emotional', 'end', 'ended',\n",
       "       'ending', 'english', 'enjoy', 'enjoyable', 'enjoyed', 'enough',\n",
       "       'entertaining', 'entertainment', 'entire', 'entirely', 'episode',\n",
       "       'era', 'escape', 'especially', 'etc', 'even', 'event',\n",
       "       'eventually', 'ever', 'every', 'everyone', 'everything', 'evil',\n",
       "       'exactly', 'example', 'excellent', 'except', 'exciting', 'expect',\n",
       "       'expected', 'expecting', 'experience', 'extra', 'extremely', 'eye',\n",
       "       'face', 'fact', 'fails', 'fairly', 'fall', 'familiar', 'family',\n",
       "       'famous', 'fan', 'fantastic', 'fantasy', 'far', 'fast', 'father',\n",
       "       'favorite', 'fear', 'feature', 'feel', 'feeling', 'felt', 'female',\n",
       "       'fight', 'fighting', 'figure', 'filled', 'film', 'filmed',\n",
       "       'filmmaker', 'final', 'finally', 'find', 'fine', 'fire', 'first',\n",
       "       'fit', 'five', 'flat', 'flaw', 'flick', 'focus', 'follow',\n",
       "       'following', 'follows', 'footage', 'force', 'forced', 'forget',\n",
       "       'form', 'former', 'forward', 'found', 'four', 'free', 'french',\n",
       "       'friend', 'front', 'full', 'fun', 'funny', 'future', 'game',\n",
       "       'gang', 'gave', 'gay', 'general', 'genius', 'genre', 'george',\n",
       "       'german', 'get', 'getting', 'ghost', 'girl', 'girlfriend', 'give',\n",
       "       'given', 'giving', 'go', 'god', 'going', 'gone', 'good', 'gore',\n",
       "       'got', 'great', 'greatest', 'group', 'guess', 'gun', 'guy', 'hair',\n",
       "       'half', 'hand', 'happen', 'happened', 'happens', 'happy', 'hard',\n",
       "       'hardly', 'hate', 'head', 'hear', 'heard', 'heart', 'hell', 'help',\n",
       "       'hero', 'high', 'highly', 'hilarious', 'history', 'hit', 'hold',\n",
       "       'hole', 'hollywood', 'home', 'honest', 'hope', 'horrible',\n",
       "       'horror', 'hot', 'hour', 'house', 'however', 'huge', 'human',\n",
       "       'humor', 'humour', 'hurt', 'husband', 'idea', 'image', 'imagine',\n",
       "       'imdb', 'important', 'impressive', 'including', 'incredible',\n",
       "       'incredibly', 'indeed', 'indian', 'inside', 'instead',\n",
       "       'intelligent', 'interest', 'interested', 'interesting', 'involved',\n",
       "       'involving', 'island', 'issue', 'italian', 'jack', 'james', 'jane',\n",
       "       'japanese', 'job', 'joe', 'john', 'joke', 'keep', 'kept', 'kid',\n",
       "       'kill', 'killed', 'killer', 'killing', 'kind', 'king', 'knew',\n",
       "       'know', 'known', 'lack', 'lady', 'lame', 'land', 'language',\n",
       "       'large', 'last', 'late', 'later', 'laugh', 'laughing', 'law', 'le',\n",
       "       'lead', 'leading', 'leaf', 'learn', 'least', 'leave', 'lee',\n",
       "       'left', 'let', 'level', 'lie', 'life', 'light', 'like', 'liked',\n",
       "       'line', 'list', 'little', 'live', 'living', 'local', 'location',\n",
       "       'long', 'longer', 'look', 'looked', 'looking', 'lost', 'lot',\n",
       "       'love', 'loved', 'lover', 'low', 'mad', 'made', 'main', 'major',\n",
       "       'make', 'maker', 'making', 'male', 'man', 'manages', 'many',\n",
       "       'mark', 'married', 'master', 'masterpiece', 'match', 'material',\n",
       "       'matter', 'may', 'maybe', 'mean', 'meaning', 'meant', 'meet',\n",
       "       'member', 'memorable', 'memory', 'men', 'mention', 'mentioned',\n",
       "       'mess', 'message', 'michael', 'middle', 'might', 'million', 'mind',\n",
       "       'minute', 'miss', 'missed', 'missing', 'mistake', 'modern',\n",
       "       'moment', 'money', 'monster', 'mostly', 'mother', 'move', 'movie',\n",
       "       'moving', 'much', 'murder', 'music', 'musical', 'must', 'mystery',\n",
       "       'name', 'named', 'nature', 'near', 'nearly', 'need', 'needed',\n",
       "       'neither', 'never', 'new', 'next', 'nice', 'night', 'none', 'nor',\n",
       "       'not', 'note', 'nothing', 'novel', 'nudity', 'number', 'obvious',\n",
       "       'obviously', 'odd', 'offer', 'office', 'often', 'okay', 'old',\n",
       "       'older', 'one', 'open', 'opening', 'opinion', 'opportunity',\n",
       "       'order', 'original', 'oscar', 'others', 'otherwise', 'outside',\n",
       "       'overall', 'pace', 'parent', 'park', 'part', 'particular',\n",
       "       'particularly', 'party', 'past', 'pathetic', 'paul', 'pay',\n",
       "       'people', 'perfect', 'perfectly', 'performance', 'perhaps',\n",
       "       'period', 'person', 'personal', 'peter', 'pick', 'picture',\n",
       "       'piece', 'place', 'plain', 'plan', 'play', 'played', 'player',\n",
       "       'playing', 'please', 'plenty', 'plot', 'plus', 'point',\n",
       "       'pointless', 'police', 'political', 'poor', 'poorly', 'popular',\n",
       "       'portrayal', 'portrayed', 'positive', 'possible', 'possibly',\n",
       "       'potential', 'power', 'powerful', 'predictable', 'premise',\n",
       "       'present', 'pretty', 'previous', 'prison', 'probably', 'problem',\n",
       "       'produced', 'producer', 'production', 'project', 'public', 'pull',\n",
       "       'pure', 'purpose', 'put', 'quality', 'question', 'quickly',\n",
       "       'quite', 'rate', 'rather', 'rating', 'read', 'reading', 'real',\n",
       "       'realistic', 'reality', 'realize', 'really', 'reason', 'recent',\n",
       "       'recently', 'recommend', 'recommended', 'red', 'relationship',\n",
       "       'release', 'released', 'remake', 'remember', 'rent', 'respect',\n",
       "       'rest', 'result', 'return', 'review', 'reviewer', 'rich',\n",
       "       'richard', 'ride', 'ridiculous', 'right', 'ring', 'road', 'robert',\n",
       "       'rock', 'role', 'romance', 'romantic', 'room', 'run', 'running',\n",
       "       'sad', 'sadly', 'said', 'save', 'saw', 'say', 'saying', 'scary',\n",
       "       'scene', 'school', 'science', 'scientist', 'score', 'scott',\n",
       "       'screen', 'screenplay', 'script', 'season', 'second', 'secret',\n",
       "       'see', 'seeing', 'seem', 'seemed', 'seems', 'seen', 'sense',\n",
       "       'sequel', 'sequence', 'series', 'serious', 'seriously', 'set',\n",
       "       'setting', 'several', 'sex', 'sexual', 'shame', 'ship', 'shoot',\n",
       "       'shooting', 'short', 'shot', 'show', 'showing', 'shown', 'sick',\n",
       "       'side', 'silly', 'similar', 'simple', 'simply', 'since', 'singing',\n",
       "       'single', 'sister', 'sit', 'situation', 'slightly', 'slow',\n",
       "       'small', 'society', 'soldier', 'solid', 'somehow', 'someone',\n",
       "       'something', 'sometimes', 'somewhat', 'son', 'song', 'soon',\n",
       "       'sorry', 'sort', 'soul', 'sound', 'soundtrack', 'space', 'speak',\n",
       "       'special', 'spend', 'spent', 'spirit', 'spoiler', 'spot', 'stage',\n",
       "       'stand', 'standard', 'star', 'start', 'started', 'state', 'stay',\n",
       "       'stick', 'still', 'stop', 'store', 'story', 'storyline',\n",
       "       'straight', 'strange', 'street', 'strong', 'student', 'studio',\n",
       "       'stuff', 'stupid', 'style', 'subject', 'success', 'successful',\n",
       "       'suck', 'suddenly', 'superb', 'supporting', 'supposed', 'sure',\n",
       "       'surprise', 'surprised', 'suspense', 'sweet', 'take', 'taken',\n",
       "       'taking', 'tale', 'talent', 'talented', 'talk', 'talking', 'taste',\n",
       "       'team', 'teen', 'teenager', 'television', 'tell', 'telling', 'ten',\n",
       "       'tension', 'term', 'terrible', 'thanks', 'theater', 'theme',\n",
       "       'thing', 'think', 'thinking', 'third', 'though', 'thought',\n",
       "       'three', 'thriller', 'throughout', 'throw', 'time', 'title',\n",
       "       'today', 'together', 'told', 'tom', 'tone', 'took', 'top', 'total',\n",
       "       'totally', 'touch', 'towards', 'town', 'track', 'trailer', 'train',\n",
       "       'tried', 'trip', 'trouble', 'true', 'truly', 'truth', 'try',\n",
       "       'trying', 'turn', 'turned', 'twist', 'two', 'type', 'typical',\n",
       "       'ultimately', 'understand', 'unfortunately', 'unique', 'unless',\n",
       "       'unlike', 'upon', 'us', 'use', 'used', 'using', 'usual', 'usually',\n",
       "       'value', 'vampire', 'van', 'various', 'version', 'victim', 'video',\n",
       "       'view', 'viewer', 'viewing', 'villain', 'violence', 'violent',\n",
       "       'visual', 'voice', 'wait', 'waiting', 'walk', 'want', 'wanted',\n",
       "       'war', 'waste', 'wasted', 'watch', 'watched', 'watching', 'water',\n",
       "       'way', 'weak', 'week', 'weird', 'well', 'went', 'western',\n",
       "       'whatever', 'whether', 'white', 'whole', 'whose', 'wife',\n",
       "       'william', 'win', 'wish', 'within', 'without', 'woman', 'wonder',\n",
       "       'wonderful', 'wood', 'word', 'work', 'worked', 'working', 'world',\n",
       "       'worse', 'worst', 'worth', 'would', 'write', 'writer', 'writing',\n",
       "       'written', 'wrong', 'wrote', 'yeah', 'year', 'yes', 'yet', 'york',\n",
       "       'young', 'younger', 'zombie'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e572243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1929ee45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accent</th>\n",
       "      <th>across</th>\n",
       "      <th>act</th>\n",
       "      <th>acted</th>\n",
       "      <th>acting</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>...</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>zombie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ability  able  absolutely  accent  across  act  acted  acting  action  \\\n",
       "0            0     0           0       0       0    0      0       2       0   \n",
       "1            0     0           0       0       0    0      0       0       0   \n",
       "2            0     0           0       0       0    0      0       0       0   \n",
       "3            0     0           0       1       0    0      0       0       0   \n",
       "4            0     0           2       0       0    0      0       0       0   \n",
       "...        ...   ...         ...     ...     ...  ...    ...     ...     ...   \n",
       "29995        0     0           0       0       0    1      0       1       0   \n",
       "29996        0     0           0       0       0    0      0       0       0   \n",
       "29997        0     0           0       0       0    0      0       0       0   \n",
       "29998        0     0           0       0       0    0      0       1       0   \n",
       "29999        0     0           0       0       0    0      0       1       0   \n",
       "\n",
       "       actor  ...  wrong  wrote  yeah  year  yes  yet  york  young  younger  \\\n",
       "0          0  ...      0      0     0     0    0    0     0      0        0   \n",
       "1          0  ...      0      0     0     0    0    0     0      0        0   \n",
       "2          0  ...      0      0     0     1    0    0     0      0        0   \n",
       "3          0  ...      0      0     0     0    0    0     0      0        0   \n",
       "4          0  ...      0      0     0     0    0    0     0      0        0   \n",
       "...      ...  ...    ...    ...   ...   ...  ...  ...   ...    ...      ...   \n",
       "29995      0  ...      0      0     0     0    0    0     0      0        0   \n",
       "29996      0  ...      0      0     0     0    0    0     0      0        0   \n",
       "29997      0  ...      0      0     0     1    0    0     0      0        0   \n",
       "29998      0  ...      1      0     0     0    0    0     0      0        0   \n",
       "29999      0  ...      0      1     0     1    0    0     0      0        0   \n",
       "\n",
       "       zombie  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "29995       0  \n",
       "29996       0  \n",
       "29997       0  \n",
       "29998       0  \n",
       "29999       0  \n",
       "\n",
       "[30000 rows x 1000 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(count_val_train.A,columns=count.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d28507f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.08"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build model\n",
    "count_mnb = MultinomialNB()\n",
    "count_mnb.fit(count_val_train.A,y_train)\n",
    "predict_count = count_mnb.predict(count_val_test.A)\n",
    "accuracy_count = accuracy_score(y_test,predict_count)*100\n",
    "accuracy_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c240f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf\n",
    "tfidf = TfidfVectorizer(max_df = 0.95,max_features=1000)\n",
    "tfidf_train = tfidf.fit_transform(clean_text_train)\n",
    "tfidf_test = tfidf.transform(clean_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ed478cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<30000x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1617735 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fcc576e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "472b3169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb28a513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ability', 'able', 'absolutely', 'accent', 'across', 'act',\n",
       "       'acted', 'acting', 'action', 'actor', 'actress', 'actual',\n",
       "       'actually', 'adaptation', 'add', 'admit', 'adult', 'adventure',\n",
       "       'age', 'ago', 'agree', 'air', 'alien', 'alive', 'almost', 'alone',\n",
       "       'along', 'already', 'also', 'although', 'always', 'amazing',\n",
       "       'america', 'american', 'among', 'amount', 'animal', 'animation',\n",
       "       'annoying', 'another', 'answer', 'anyone', 'anything', 'anyway',\n",
       "       'apart', 'apparently', 'appeal', 'appear', 'appearance', 'appears',\n",
       "       'appreciate', 'army', 'around', 'art', 'aside', 'ask', 'aspect',\n",
       "       'atmosphere', 'attack', 'attempt', 'attention', 'audience',\n",
       "       'average', 'avoid', 'award', 'away', 'awesome', 'awful', 'baby',\n",
       "       'back', 'background', 'bad', 'badly', 'band', 'barely', 'based',\n",
       "       'basic', 'basically', 'battle', 'beautiful', 'beauty', 'became',\n",
       "       'become', 'becomes', 'begin', 'beginning', 'behind', 'belief',\n",
       "       'believable', 'believe', 'best', 'better', 'beyond', 'big',\n",
       "       'biggest', 'bill', 'bit', 'bizarre', 'black', 'blood', 'blue',\n",
       "       'body', 'book', 'bored', 'boring', 'bother', 'box', 'boy', 'brain',\n",
       "       'break', 'brilliant', 'bring', 'brings', 'british', 'brother',\n",
       "       'brought', 'budget', 'bunch', 'business', 'buy', 'call', 'called',\n",
       "       'came', 'camera', 'camp', 'car', 'care', 'career', 'carry',\n",
       "       'cartoon', 'case', 'cast', 'casting', 'cat', 'catch', 'caught',\n",
       "       'century', 'certain', 'certainly', 'chance', 'change', 'changed',\n",
       "       'channel', 'character', 'chase', 'cheap', 'check', 'cheesy',\n",
       "       'child', 'choice', 'christmas', 'cinema', 'cinematography', 'city',\n",
       "       'class', 'classic', 'clear', 'clearly', 'clever', 'cliche',\n",
       "       'close', 'college', 'color', 'come', 'comedy', 'comic', 'coming',\n",
       "       'comment', 'common', 'company', 'compared', 'complete',\n",
       "       'completely', 'computer', 'concept', 'conclusion', 'consider',\n",
       "       'considering', 'control', 'convincing', 'cool', 'cop', 'copy',\n",
       "       'costume', 'could', 'country', 'couple', 'course', 'cover', 'crap',\n",
       "       'crazy', 'create', 'created', 'creature', 'credit', 'creepy',\n",
       "       'crew', 'crime', 'critic', 'cry', 'culture', 'cut', 'cute',\n",
       "       'dance', 'dancing', 'dark', 'date', 'daughter', 'david', 'day',\n",
       "       'dead', 'deal', 'death', 'decent', 'decide', 'decided', 'decides',\n",
       "       'deep', 'definitely', 'depth', 'deserves', 'despite', 'detail',\n",
       "       'development', 'dialog', 'dialogue', 'die', 'died', 'different',\n",
       "       'difficult', 'directed', 'directing', 'direction', 'director',\n",
       "       'disappointed', 'disney', 'doctor', 'documentary', 'dog', 'done',\n",
       "       'door', 'doubt', 'drama', 'dramatic', 'dream', 'drive', 'drug',\n",
       "       'due', 'dull', 'dumb', 'dvd', 'earlier', 'early', 'earth',\n",
       "       'easily', 'easy', 'editing', 'effect', 'effort', 'either',\n",
       "       'element', 'else', 'emotion', 'emotional', 'end', 'ended',\n",
       "       'ending', 'english', 'enjoy', 'enjoyable', 'enjoyed', 'enough',\n",
       "       'entertaining', 'entertainment', 'entire', 'entirely', 'episode',\n",
       "       'era', 'escape', 'especially', 'etc', 'even', 'event',\n",
       "       'eventually', 'ever', 'every', 'everyone', 'everything', 'evil',\n",
       "       'exactly', 'example', 'excellent', 'except', 'exciting', 'expect',\n",
       "       'expected', 'expecting', 'experience', 'extra', 'extremely', 'eye',\n",
       "       'face', 'fact', 'fails', 'fairly', 'fall', 'familiar', 'family',\n",
       "       'famous', 'fan', 'fantastic', 'fantasy', 'far', 'fast', 'father',\n",
       "       'favorite', 'fear', 'feature', 'feel', 'feeling', 'felt', 'female',\n",
       "       'fight', 'fighting', 'figure', 'filled', 'film', 'filmed',\n",
       "       'filmmaker', 'final', 'finally', 'find', 'fine', 'fire', 'first',\n",
       "       'fit', 'five', 'flat', 'flaw', 'flick', 'focus', 'follow',\n",
       "       'following', 'follows', 'footage', 'force', 'forced', 'forget',\n",
       "       'form', 'former', 'forward', 'found', 'four', 'free', 'french',\n",
       "       'friend', 'front', 'full', 'fun', 'funny', 'future', 'game',\n",
       "       'gang', 'gave', 'gay', 'general', 'genius', 'genre', 'george',\n",
       "       'german', 'get', 'getting', 'ghost', 'girl', 'girlfriend', 'give',\n",
       "       'given', 'giving', 'go', 'god', 'going', 'gone', 'good', 'gore',\n",
       "       'got', 'great', 'greatest', 'group', 'guess', 'gun', 'guy', 'hair',\n",
       "       'half', 'hand', 'happen', 'happened', 'happens', 'happy', 'hard',\n",
       "       'hardly', 'hate', 'head', 'hear', 'heard', 'heart', 'hell', 'help',\n",
       "       'hero', 'high', 'highly', 'hilarious', 'history', 'hit', 'hold',\n",
       "       'hole', 'hollywood', 'home', 'honest', 'hope', 'horrible',\n",
       "       'horror', 'hot', 'hour', 'house', 'however', 'huge', 'human',\n",
       "       'humor', 'humour', 'hurt', 'husband', 'idea', 'image', 'imagine',\n",
       "       'imdb', 'important', 'impressive', 'including', 'incredible',\n",
       "       'incredibly', 'indeed', 'indian', 'inside', 'instead',\n",
       "       'intelligent', 'interest', 'interested', 'interesting', 'involved',\n",
       "       'involving', 'island', 'issue', 'italian', 'jack', 'james', 'jane',\n",
       "       'japanese', 'job', 'joe', 'john', 'joke', 'keep', 'kept', 'kid',\n",
       "       'kill', 'killed', 'killer', 'killing', 'kind', 'king', 'knew',\n",
       "       'know', 'known', 'lack', 'lady', 'lame', 'land', 'language',\n",
       "       'large', 'last', 'late', 'later', 'laugh', 'laughing', 'law', 'le',\n",
       "       'lead', 'leading', 'leaf', 'learn', 'least', 'leave', 'lee',\n",
       "       'left', 'let', 'level', 'lie', 'life', 'light', 'like', 'liked',\n",
       "       'line', 'list', 'little', 'live', 'living', 'local', 'location',\n",
       "       'long', 'longer', 'look', 'looked', 'looking', 'lost', 'lot',\n",
       "       'love', 'loved', 'lover', 'low', 'mad', 'made', 'main', 'major',\n",
       "       'make', 'maker', 'making', 'male', 'man', 'manages', 'many',\n",
       "       'mark', 'married', 'master', 'masterpiece', 'match', 'material',\n",
       "       'matter', 'may', 'maybe', 'mean', 'meaning', 'meant', 'meet',\n",
       "       'member', 'memorable', 'memory', 'men', 'mention', 'mentioned',\n",
       "       'mess', 'message', 'michael', 'middle', 'might', 'million', 'mind',\n",
       "       'minute', 'miss', 'missed', 'missing', 'mistake', 'modern',\n",
       "       'moment', 'money', 'monster', 'mostly', 'mother', 'move', 'movie',\n",
       "       'moving', 'much', 'murder', 'music', 'musical', 'must', 'mystery',\n",
       "       'name', 'named', 'nature', 'near', 'nearly', 'need', 'needed',\n",
       "       'neither', 'never', 'new', 'next', 'nice', 'night', 'none', 'nor',\n",
       "       'not', 'note', 'nothing', 'novel', 'nudity', 'number', 'obvious',\n",
       "       'obviously', 'odd', 'offer', 'office', 'often', 'okay', 'old',\n",
       "       'older', 'one', 'open', 'opening', 'opinion', 'opportunity',\n",
       "       'order', 'original', 'oscar', 'others', 'otherwise', 'outside',\n",
       "       'overall', 'pace', 'parent', 'park', 'part', 'particular',\n",
       "       'particularly', 'party', 'past', 'pathetic', 'paul', 'pay',\n",
       "       'people', 'perfect', 'perfectly', 'performance', 'perhaps',\n",
       "       'period', 'person', 'personal', 'peter', 'pick', 'picture',\n",
       "       'piece', 'place', 'plain', 'plan', 'play', 'played', 'player',\n",
       "       'playing', 'please', 'plenty', 'plot', 'plus', 'point',\n",
       "       'pointless', 'police', 'political', 'poor', 'poorly', 'popular',\n",
       "       'portrayal', 'portrayed', 'positive', 'possible', 'possibly',\n",
       "       'potential', 'power', 'powerful', 'predictable', 'premise',\n",
       "       'present', 'pretty', 'previous', 'prison', 'probably', 'problem',\n",
       "       'produced', 'producer', 'production', 'project', 'public', 'pull',\n",
       "       'pure', 'purpose', 'put', 'quality', 'question', 'quickly',\n",
       "       'quite', 'rate', 'rather', 'rating', 'read', 'reading', 'real',\n",
       "       'realistic', 'reality', 'realize', 'really', 'reason', 'recent',\n",
       "       'recently', 'recommend', 'recommended', 'red', 'relationship',\n",
       "       'release', 'released', 'remake', 'remember', 'rent', 'respect',\n",
       "       'rest', 'result', 'return', 'review', 'reviewer', 'rich',\n",
       "       'richard', 'ride', 'ridiculous', 'right', 'ring', 'road', 'robert',\n",
       "       'rock', 'role', 'romance', 'romantic', 'room', 'run', 'running',\n",
       "       'sad', 'sadly', 'said', 'save', 'saw', 'say', 'saying', 'scary',\n",
       "       'scene', 'school', 'science', 'scientist', 'score', 'scott',\n",
       "       'screen', 'screenplay', 'script', 'season', 'second', 'secret',\n",
       "       'see', 'seeing', 'seem', 'seemed', 'seems', 'seen', 'sense',\n",
       "       'sequel', 'sequence', 'series', 'serious', 'seriously', 'set',\n",
       "       'setting', 'several', 'sex', 'sexual', 'shame', 'ship', 'shoot',\n",
       "       'shooting', 'short', 'shot', 'show', 'showing', 'shown', 'sick',\n",
       "       'side', 'silly', 'similar', 'simple', 'simply', 'since', 'singing',\n",
       "       'single', 'sister', 'sit', 'situation', 'slightly', 'slow',\n",
       "       'small', 'society', 'soldier', 'solid', 'somehow', 'someone',\n",
       "       'something', 'sometimes', 'somewhat', 'son', 'song', 'soon',\n",
       "       'sorry', 'sort', 'soul', 'sound', 'soundtrack', 'space', 'speak',\n",
       "       'special', 'spend', 'spent', 'spirit', 'spoiler', 'spot', 'stage',\n",
       "       'stand', 'standard', 'star', 'start', 'started', 'state', 'stay',\n",
       "       'stick', 'still', 'stop', 'store', 'story', 'storyline',\n",
       "       'straight', 'strange', 'street', 'strong', 'student', 'studio',\n",
       "       'stuff', 'stupid', 'style', 'subject', 'success', 'successful',\n",
       "       'suck', 'suddenly', 'superb', 'supporting', 'supposed', 'sure',\n",
       "       'surprise', 'surprised', 'suspense', 'sweet', 'take', 'taken',\n",
       "       'taking', 'tale', 'talent', 'talented', 'talk', 'talking', 'taste',\n",
       "       'team', 'teen', 'teenager', 'television', 'tell', 'telling', 'ten',\n",
       "       'tension', 'term', 'terrible', 'thanks', 'theater', 'theme',\n",
       "       'thing', 'think', 'thinking', 'third', 'though', 'thought',\n",
       "       'three', 'thriller', 'throughout', 'throw', 'time', 'title',\n",
       "       'today', 'together', 'told', 'tom', 'tone', 'took', 'top', 'total',\n",
       "       'totally', 'touch', 'towards', 'town', 'track', 'trailer', 'train',\n",
       "       'tried', 'trip', 'trouble', 'true', 'truly', 'truth', 'try',\n",
       "       'trying', 'turn', 'turned', 'twist', 'two', 'type', 'typical',\n",
       "       'ultimately', 'understand', 'unfortunately', 'unique', 'unless',\n",
       "       'unlike', 'upon', 'us', 'use', 'used', 'using', 'usual', 'usually',\n",
       "       'value', 'vampire', 'van', 'various', 'version', 'victim', 'video',\n",
       "       'view', 'viewer', 'viewing', 'villain', 'violence', 'violent',\n",
       "       'visual', 'voice', 'wait', 'waiting', 'walk', 'want', 'wanted',\n",
       "       'war', 'waste', 'wasted', 'watch', 'watched', 'watching', 'water',\n",
       "       'way', 'weak', 'week', 'weird', 'well', 'went', 'western',\n",
       "       'whatever', 'whether', 'white', 'whole', 'whose', 'wife',\n",
       "       'william', 'win', 'wish', 'within', 'without', 'woman', 'wonder',\n",
       "       'wonderful', 'wood', 'word', 'work', 'worked', 'working', 'world',\n",
       "       'worse', 'worst', 'worth', 'would', 'write', 'writer', 'writing',\n",
       "       'written', 'wrong', 'wrote', 'yeah', 'year', 'yes', 'yet', 'york',\n",
       "       'young', 'younger', 'zombie'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f67e1613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80e8600f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accent</th>\n",
       "      <th>across</th>\n",
       "      <th>act</th>\n",
       "      <th>acted</th>\n",
       "      <th>acting</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>...</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>zombie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055835</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137927</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321532</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07508</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.18909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.102630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ability  able  absolutely    accent  across       act  acted    acting  \\\n",
       "0          0.0   0.0    0.000000  0.000000     0.0  0.000000    0.0  0.182468   \n",
       "1          0.0   0.0    0.000000  0.000000     0.0  0.000000    0.0  0.000000   \n",
       "2          0.0   0.0    0.000000  0.000000     0.0  0.000000    0.0  0.000000   \n",
       "3          0.0   0.0    0.000000  0.137927     0.0  0.000000    0.0  0.000000   \n",
       "4          0.0   0.0    0.321532  0.000000     0.0  0.000000    0.0  0.000000   \n",
       "...        ...   ...         ...       ...     ...       ...    ...       ...   \n",
       "29995      0.0   0.0    0.000000  0.000000     0.0  0.135608    0.0  0.088056   \n",
       "29996      0.0   0.0    0.000000  0.000000     0.0  0.000000    0.0  0.000000   \n",
       "29997      0.0   0.0    0.000000  0.000000     0.0  0.000000    0.0  0.000000   \n",
       "29998      0.0   0.0    0.000000  0.000000     0.0  0.000000    0.0  0.050570   \n",
       "29999      0.0   0.0    0.000000  0.000000     0.0  0.000000    0.0  0.097604   \n",
       "\n",
       "       action  actor  ...    wrong    wrote  yeah      year  yes  yet  york  \\\n",
       "0         0.0    0.0  ...  0.00000  0.00000   0.0  0.000000  0.0  0.0   0.0   \n",
       "1         0.0    0.0  ...  0.00000  0.00000   0.0  0.000000  0.0  0.0   0.0   \n",
       "2         0.0    0.0  ...  0.00000  0.00000   0.0  0.055835  0.0  0.0   0.0   \n",
       "3         0.0    0.0  ...  0.00000  0.00000   0.0  0.000000  0.0  0.0   0.0   \n",
       "4         0.0    0.0  ...  0.00000  0.00000   0.0  0.000000  0.0  0.0   0.0   \n",
       "...       ...    ...  ...      ...      ...   ...       ...  ...  ...   ...   \n",
       "29995     0.0    0.0  ...  0.00000  0.00000   0.0  0.000000  0.0  0.0   0.0   \n",
       "29996     0.0    0.0  ...  0.00000  0.00000   0.0  0.000000  0.0  0.0   0.0   \n",
       "29997     0.0    0.0  ...  0.00000  0.00000   0.0  0.074142  0.0  0.0   0.0   \n",
       "29998     0.0    0.0  ...  0.07508  0.00000   0.0  0.000000  0.0  0.0   0.0   \n",
       "29999     0.0    0.0  ...  0.00000  0.18909   0.0  0.102630  0.0  0.0   0.0   \n",
       "\n",
       "       young  younger  zombie  \n",
       "0        0.0      0.0     0.0  \n",
       "1        0.0      0.0     0.0  \n",
       "2        0.0      0.0     0.0  \n",
       "3        0.0      0.0     0.0  \n",
       "4        0.0      0.0     0.0  \n",
       "...      ...      ...     ...  \n",
       "29995    0.0      0.0     0.0  \n",
       "29996    0.0      0.0     0.0  \n",
       "29997    0.0      0.0     0.0  \n",
       "29998    0.0      0.0     0.0  \n",
       "29999    0.0      0.0     0.0  \n",
       "\n",
       "[30000 rows x 1000 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tfidf_train.A,columns=tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b08acd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.66"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build model\n",
    "tfidf_mnb = MultinomialNB()\n",
    "tfidf_mnb.fit(tfidf_train.A,y_train)\n",
    "predict_tfidf = tfidf_mnb.predict(tfidf_test.A)\n",
    "accuracy_tfidf = accuracy_score(y_test,predict_tfidf)*100\n",
    "accuracy_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a64c48bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32823    [central, theme, movie, seems, confusion, rela...\n",
       "16298    [excellent, example, cowboy, noir, called, une...\n",
       "28505    [ending, made, heart, jump, throat, proceeded,...\n",
       "6689     [chosen, one, appreciate, quality, story, char...\n",
       "26893    [really, funny, film, especially, second, thir...\n",
       "                               ...                        \n",
       "29415    [film, came, gift, offering, blue, unlike, rev...\n",
       "11359    [first, started, watching, movie, looking, kin...\n",
       "575      [big, mark, music, neil, young, glowing, prais...\n",
       "17398    [watching, lady, ermine, wondering, betty, gra...\n",
       "4189     [crappy, miserably, acted, movie, based, subli...\n",
       "Name: text, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ngrams\n",
    "from nltk.util import ngrams\n",
    "def splitting_dataframe(data):\n",
    "    tokens = data.split()\n",
    "    return tokens\n",
    "\n",
    "data = clean_text_test.apply(splitting_dataframe)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a451111d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_list(data,ngram_range):\n",
    "    ngram = ngrams(data,ngram_range)# zip file\n",
    "    ngram_list1 = []\n",
    "    for ngram1 in ngram:#opening zip file\n",
    "        ngram_list1.append(' '.join(ngram1))\n",
    "    return ngram_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bdfaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_range >>1 >>unigrams \n",
    "            >>2 >>bigrams\n",
    "            >>3 >>trigrams \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12b54535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32823    [central, theme, movie, seems, confusion, rela...\n",
       "16298    [excellent, example, cowboy, noir, called, une...\n",
       "28505    [ending, made, heart, jump, throat, proceeded,...\n",
       "6689     [chosen, one, appreciate, quality, story, char...\n",
       "26893    [really, funny, film, especially, second, thir...\n",
       "                               ...                        \n",
       "29415    [film, came, gift, offering, blue, unlike, rev...\n",
       "11359    [first, started, watching, movie, looking, kin...\n",
       "575      [big, mark, music, neil, young, glowing, prais...\n",
       "17398    [watching, lady, ermine, wondering, betty, gra...\n",
       "4189     [crappy, miserably, acted, movie, based, subli...\n",
       "Name: text, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigrams = data.apply(lambda x : ngram_list(x,1))\n",
    "unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "431745fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32823    [central theme, theme movie, movie seems, seem...\n",
       "16298    [excellent example, example cowboy, cowboy noi...\n",
       "28505    [ending made, made heart, heart jump, jump thr...\n",
       "6689     [chosen one, one appreciate, appreciate qualit...\n",
       "26893    [really funny, funny film, film especially, es...\n",
       "                               ...                        \n",
       "29415    [film came, came gift, gift offering, offering...\n",
       "11359    [first started, started watching, watching mov...\n",
       "575      [big mark, mark music, music neil, neil young,...\n",
       "17398    [watching lady, lady ermine, ermine wondering,...\n",
       "4189     [crappy miserably, miserably acted, acted movi...\n",
       "Name: text, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams = data.apply(lambda x : ngram_list(x,2))\n",
    "bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93371d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32823    [central theme movie, theme movie seems, movie...\n",
       "16298    [excellent example cowboy, example cowboy noir...\n",
       "28505    [ending made heart, made heart jump, heart jum...\n",
       "6689     [chosen one appreciate, one appreciate quality...\n",
       "26893    [really funny film, funny film especially, fil...\n",
       "                               ...                        \n",
       "29415    [film came gift, came gift offering, gift offe...\n",
       "11359    [first started watching, started watching movi...\n",
       "575      [big mark music, mark music neil, music neil y...\n",
       "17398    [watching lady ermine, lady ermine wondering, ...\n",
       "4189     [crappy miserably acted, miserably acted movie...\n",
       "Name: text, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams = data.apply(lambda x : ngram_list(x,3))\n",
    "trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34c9ad1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32823    [central theme movie seems confusion relations...\n",
       "16298    [excellent example cowboy noir called unemploy...\n",
       "28505    [ending made heart jump throat proceeded leave...\n",
       "6689     [chosen one appreciate quality story character...\n",
       "26893    [really funny film especially second third fou...\n",
       "                               ...                        \n",
       "29415    [film came gift offering blue unlike reviewer,...\n",
       "11359    [first started watching movie looking kind sub...\n",
       "575      [big mark music neil young glowing praise, mar...\n",
       "17398    [watching lady ermine wondering betty grable p...\n",
       "4189     [crappy miserably acted movie based sublimated...\n",
       "Name: text, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams = data.apply(lambda x : ngram_list(x,7))\n",
    "trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fce4a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91714d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
